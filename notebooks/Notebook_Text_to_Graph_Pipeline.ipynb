{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import en_core_web_lg\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../diagram.png\" style=\"height: 50px; width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods investigated Flowchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Darth Vader, also known by his birth name Anakin Skywalker, is a fictional character in the Star Wars franchise. Darth Vader appears in the original film trilogy as a pivotal antagonist whose actions drive the plot, while his past as Anakin Skywalker and the story of his corruption are central to the narrative of the prequel trilogy. The character was created by George Lucas and has been portrayed by numerous actors. His appearances span the first six Star Wars films, as well as Rogue One, and his character is heavily referenced in Star Wars: The Force Awakens. He is also an important character in the Star Wars expanded universe of television series, video games, novels, literature and comic books. Originally a Jedi who was prophesied to bring balance to the Force, he falls to the dark side of the Force and serves the evil Galactic Empire at the right hand of his Sith master, Emperor Palpatine (also known as Darth Sidious).'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starwars_text = 'Darth Vader, also known by his birth name Anakin Skywalker, is a fictional character in the Star Wars franchise. Darth Vader appears in the original film trilogy as a pivotal antagonist whose actions drive the plot, while his past as Anakin Skywalker and the story of his corruption are central to the narrative of the prequel trilogy. The character was created by George Lucas and has been portrayed by numerous actors. His appearances span the first six Star Wars films, as well as Rogue One, and his character is heavily referenced in Star Wars: The Force Awakens. He is also an important character in the Star Wars expanded universe of television series, video games, novels, literature and comic books. Originally a Jedi who was prophesied to bring balance to the Force, he falls to the dark side of the Force and serves the evil Galactic Empire at the right hand of his Sith master, Emperor Palpatine (also known as Darth Sidious).'\n",
    "starwars_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Iron Man is a fictional superhero appearing in American comic books published by Marvel Comics. The character was co-created by writer and editor Stan Lee, developed by scripter Larry Lieber, and designed by artists Don Heck and Jack Kirby. The character made his first appearance in Tales of Suspense #39 (cover dated March 1963), and received his own title in Iron Man #1 (May 1968). Also in 1963, the character founded the Avengers alongside Thor, Ant-Man, Wasp and the Hulk. A wealthy American business magnate, playboy, philanthropist, inventor and ingenious scientist, Anthony Edward \"Tony\" Stark suffers a severe chest injury during a kidnapping. When his captors attempt to force him to build a weapon of mass destruction, he instead creates a mechanized suit of armor to save his life and escape captivity. Later, Stark develops his suit, adding weapons and other technological devices he designed through his company, Stark Industries. He uses the suit and successive versions to protect the world as Iron Man. Although at first concealing his true identity, Stark eventually publicly reveals himself to be Iron Man. Initially, Iron Man was a vehicle for Stan Lee to explore Cold War themes, particularly the role of American technology and industry in the fight against communism. Subsequent re-imaginings of Iron Man have transitioned from Cold War motifs to contemporary matters of the time. Throughout most of the character\\'s publication history, Iron Man has been a founding member of the superhero team the Avengers and has been featured in several incarnations of his own various comic book series. Iron Man has been adapted for several animated TV shows and films. The Marvel Cinematic Universe character was portrayed by Robert Downey Jr. in the Marvel Cinematic Universe films Iron Man (2008), The Incredible Hulk (2008) in a cameo, Iron Man 2 (2010), The Avengers (2012), Iron Man 3 (2013), Avengers: Age of Ultron (2015), Captain America: Civil War (2016), Spider-Man: Homecoming (2017), Avengers: Infinity War (2018) and Avengers: Endgame (2019). The character also appeared in Spider-Man: Far From Home (2019) and in the upcoming Black Widow (2021) through archive footage.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starwars_text = '''Iron Man is a fictional superhero appearing in American comic books published by Marvel Comics. The character was co-created by writer and editor Stan Lee, developed by scripter Larry Lieber, and designed by artists Don Heck and Jack Kirby. The character made his first appearance in Tales of Suspense #39 (cover dated March 1963), and received his own title in Iron Man #1 (May 1968). Also in 1963, the character founded the Avengers alongside Thor, Ant-Man, Wasp and the Hulk. A wealthy American business magnate, playboy, philanthropist, inventor and ingenious scientist, Anthony Edward \"Tony\" Stark suffers a severe chest injury during a kidnapping. When his captors attempt to force him to build a weapon of mass destruction, he instead creates a mechanized suit of armor to save his life and escape captivity. Later, Stark develops his suit, adding weapons and other technological devices he designed through his company, Stark Industries. He uses the suit and successive versions to protect the world as Iron Man. Although at first concealing his true identity, Stark eventually publicly reveals himself to be Iron Man. Initially, Iron Man was a vehicle for Stan Lee to explore Cold War themes, particularly the role of American technology and industry in the fight against communism. Subsequent re-imaginings of Iron Man have transitioned from Cold War motifs to contemporary matters of the time. Throughout most of the character's publication history, Iron Man has been a founding member of the superhero team the Avengers and has been featured in several incarnations of his own various comic book series. Iron Man has been adapted for several animated TV shows and films. The Marvel Cinematic Universe character was portrayed by Robert Downey Jr. in the Marvel Cinematic Universe films Iron Man (2008), The Incredible Hulk (2008) in a cameo, Iron Man 2 (2010), The Avengers (2012), Iron Man 3 (2013), Avengers: Age of Ultron (2015), Captain America: Civil War (2016), Spider-Man: Homecoming (2017), Avengers: Infinity War (2018) and Avengers: Endgame (2019). The character also appeared in Spider-Man: Far From Home (2019) and in the upcoming Black Widow (2021) through archive footage.'''\n",
    "starwars_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: 6 sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpaCy NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Iron Man': 'PERSON',\n",
       " 'American': 'NORP',\n",
       " 'Marvel Comics': 'ORG',\n",
       " 'Stan Lee': 'PERSON',\n",
       " 'Larry Lieber': 'PERSON',\n",
       " 'Don Heck': 'PERSON',\n",
       " 'Jack Kirby': 'PERSON',\n",
       " 'first': 'ORDINAL',\n",
       " 'Tales of Suspense': 'WORK_OF_ART',\n",
       " '39': 'MONEY',\n",
       " 'March 1963': 'DATE',\n",
       " '#1': 'CARDINAL',\n",
       " 'May 1968': 'DATE',\n",
       " '1963': 'DATE',\n",
       " 'Avengers': 'WORK_OF_ART',\n",
       " 'Thor': 'ORG',\n",
       " 'Ant-Man': 'PRODUCT',\n",
       " 'Wasp': 'PERSON',\n",
       " 'Hulk': 'WORK_OF_ART',\n",
       " 'playboy': 'ORG',\n",
       " 'Anthony Edward \"Tony\" Stark': 'PERSON',\n",
       " 'Stark': 'PERSON',\n",
       " 'Stark Industries': 'ORG',\n",
       " 'Cold War': 'EVENT',\n",
       " 'The Marvel Cinematic Universe': 'WORK_OF_ART',\n",
       " 'Robert Downey Jr.': 'PERSON',\n",
       " 'the Marvel Cinematic Universe films Iron Man': 'ORG',\n",
       " 'The Incredible Hulk': 'WORK_OF_ART',\n",
       " '2010': 'DATE',\n",
       " '2012': 'DATE',\n",
       " '3': 'CARDINAL',\n",
       " '2013': 'DATE',\n",
       " 'Ultron': 'ORG',\n",
       " '2015': 'DATE',\n",
       " '2016': 'DATE',\n",
       " '2017': 'DATE',\n",
       " 'Avengers: Infinity War (2018': 'WORK_OF_ART',\n",
       " '2019': 'DATE',\n",
       " 'Spider-Man:': 'WORK_OF_ART',\n",
       " 'Black Widow': 'WORK_OF_ART',\n",
       " '2021': 'DATE'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "doc = nlp(starwars_text)\n",
    "\n",
    "ner_dict = {}\n",
    "for x in doc.ents:\n",
    "    ner_dict[x.text] = x.label_\n",
    "ner_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Does not perform well at all compared to SpaCy NER. Able to recognize PERSONs but not in partial fragments. Not able to recognize entities other than LOCATION or PERSON such as WORK_OF_ART or DATE, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NLTK\n",
    "# # sentences = nltk.sent_tokenize(starwars_text)\n",
    "\n",
    "# spaCy\n",
    "run_this=0\n",
    "if run_this==1:\n",
    "    nlp = spacy.lang.en.English()\n",
    "    nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "    doc = nlp(starwars_text)\n",
    "    sentences = [sent.string.strip() for sent in doc.sents]\n",
    "\n",
    "    ner_tagger = nltk.tag.StanfordNERTagger(\"./stanford-ner-2018-10-16/classifiers/english.all.3class.distsim.crf.ser.gz\", \"./stanford-ner-2018-10-16/stanford-ner.jar\")\n",
    "\n",
    "    ner_dict = {}\n",
    "    results = []\n",
    "\n",
    "    nlp = spacy.lang.en.English()\n",
    "    tokenizer = spacy.tokenizer.Tokenizer(nlp.vocab)\n",
    "    for sent in sentences:\n",
    "        words = [token.orth_ for token in tokenizer(sent)]\n",
    "        print(words)\n",
    "        tagged = ner_tagger.tag(words)\n",
    "        results += tagged\n",
    "\n",
    "    for res in results:\n",
    "        ner_dict[res[0]] = res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coreference Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Look into Neural Coref from Huggingface: https://github.com/huggingface/neuralcoref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look into CoreNLP base model for Python\n",
    "https://stanfordnlp.github.io/CoreNLP/coref.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> fixed root permission error: https://github.com/Lynten/stanford-corenlp/issues/26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate coreferences and dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP(\"./stanford-corenlp-4.2.0\", quiet=False)\n",
    "annotated = nlp.annotate(starwars_text, properties={'annotators': 'coref', 'pipelineLanguage': 'en'})\n",
    "result = json.loads(annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corefs = result['corefs']\n",
    "corefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolve coreferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corefs = result['corefs']\n",
    "print(\"Coreferences found: \",len(corefs))\n",
    "print(\"Named entities: \" , ner_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_coref_with = []\n",
    "sentence_wise_replacements = defaultdict(list) \n",
    "sentence_wise_replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(starwars_text)\n",
    "# nlp = spacy.lang.en.English()\n",
    "# nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "# doc = nlp(starwars_text)\n",
    "# sentences = [sent.string.strip() for sent in doc.sents]\n",
    "\n",
    "print('Number of sentences: ', len(sentences))\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Here, nltk sentence tokenizer is more accurate than spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize corefs and replacements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,coreferences in enumerate(corefs.values()):\n",
    "    replace_with = coreferences[0]\n",
    "    for reference in coreferences:\n",
    "        if reference[\"text\"] in ner_dict.keys() or reference[\"text\"][reference[\"headIndex\"]-reference[\"startIndex\"]] in ner_dict.keys():\n",
    "            replace_with = reference\n",
    "        sentence_wise_replacements[reference[\"sentNum\"]-1].append((reference,index))\n",
    "    replace_coref_with.append(replace_with[\"text\"])  \n",
    "\n",
    "sentence_wise_replacements[0].sort(key=lambda tup: tup[0][\"startIndex\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pronoun Replacement with Named Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.lang.en.English()\n",
    "# tokenizer = spacy.tokenizer.Tokenizer(nlp.vocab)\n",
    "tokenizer = nltk.word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carry out replacement\n",
    "for index,sent in enumerate(sentences):\n",
    "    replacement_list = sentence_wise_replacements[index]    \n",
    "    for item in replacement_list[::-1]:                     \n",
    "        to_replace = item[0]                                \n",
    "        replace_with = replace_coref_with[item[1]]\n",
    "        replaced_sent = \"\"\n",
    "        words = tokenizer(sent)\n",
    "        \n",
    "        \n",
    "        for i in range(len(words)-1,to_replace[\"endIndex\"]-2,-1):\n",
    "            replaced_sent = words[i] + \" \" + replaced_sent\n",
    "        \n",
    "        replaced_sent = replace_with + \" \" + replaced_sent\n",
    "        \n",
    "        for i in range(to_replace[\"startIndex\"]-2,-1,-1):\n",
    "            replaced_sent = words[i] + \" \" + replaced_sent\n",
    "        \n",
    "        #print(replaced_sent)\n",
    "        sentences[index] = replaced_sent\n",
    "\n",
    "result = \"\"\n",
    "for sent in sentences:\n",
    "    result += sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starwars_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: fix the weird spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation Extraction of using Stanford OpenIE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subject removal -> not URI (Literals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from openie import StanfordOpenIE\n",
    "\n",
    "triples = []\n",
    "with StanfordOpenIE() as client:\n",
    "    for triple in client.annotate(result):\n",
    "        triples.append(triple)\n",
    "        \n",
    "triples = pd.DataFrame(triples)\n",
    "triples.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Try out MinIE and/or Allenai OpenIE-standalone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity and Triple Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_set = set(ner_dict.keys())\n",
    "entity_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Following needs to be optimized to reduce loss of knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_triples = []\n",
    "for row, col in triples.iterrows():\n",
    "    col['subject'] = col['subject'].strip()\n",
    "\n",
    "    # check if Named Entity in subject sentence fragment\n",
    "    found_entity = False\n",
    "    for named_entity in entity_set:\n",
    "        if named_entity in col['subject']:\n",
    "            col['subject'] = named_entity\n",
    "            found_entity = True\n",
    "\n",
    "    if found_entity:\n",
    "        added = False\n",
    "        entity2_sent = col['object']\n",
    "        for entity in entity_set:\n",
    "#             if entity in entity2_sent:\n",
    "#                 final_triples.append(\n",
    "#                     (ner_dict[col['subject']], col['subject'], col['relation'], 'O', col['object']))\n",
    "#                 added = True\n",
    "#         if not added:\n",
    "            final_triples.append(('Node', col['subject'], col['relation'], 'Node', col['object']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(final_triples, columns=['Type1','Entity1','Relationship','Type2', 'Entity2']).drop_duplicates()\n",
    "final_df\n",
    "# final_df.to_csv('starwars1_processed.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> starwars1_processed Graph Visualization: https://graphcommons.com/graphs/01252887-9a23-4b33-a06d-02729a330beb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Graph, using Stanford NER: https://graphcommons.com/graphs/1f5d76f7-69ad-4575-83dd-4c90afab7059"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triple Linking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note this is limited due to average of word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_trf_bertbaseuncased_lg\n",
    "nlp = en_trf_bertbaseuncased_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for _,col1 in final_df.iterrows():\n",
    "    head = col1['Entity2']\n",
    "    doc1 = nlp(head)\n",
    "    \n",
    "    for _,col2 in final_df.iterrows():\n",
    "        tail = col2['Entity2']\n",
    "        if head == tail:\n",
    "            continue\n",
    "            \n",
    "        doc2 = nlp(tail)\n",
    "        confidence = doc1.similarity(doc2)\n",
    "        \n",
    "        if confidence > 0.85:   # 85% seems to work pretty well\n",
    "            # Perform logic for linking\n",
    "            new_tail = head if len(tail)<len(head) else tail\n",
    "            \n",
    "            col1['Entity2'] = new_tail\n",
    "            col2['Entity2'] = new_tail\n",
    "\n",
    "            print(\"Sentence 1:\", doc1)\n",
    "            print(\"Sentence 2:\", doc2)\n",
    "            print(\"Similarity:\", confidence)\n",
    "            index += 1\n",
    "            print('Processed {} out of {}'.format(index,len(final_df)))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.drop_duplicates()\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('starwars_linked_processed.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://graphcommons.com/graphs/aae63b3e-870d-4c2e-83e4-bbca9f297b42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://github.com/UKPLab/sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "# bert-base-nli-mean-tokens\n",
    "# https://huggingface.co/sentence-transformers/bert-base-nli-mean-tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.4579\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: 0.1759\n",
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.9283\n"
     ]
    }
   ],
   "source": [
    "sentences1 = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'The new movie is awesome']\n",
    "\n",
    "sentences2 = ['The dog plays in the garden',\n",
    "              'A woman watches TV',\n",
    "              'The new movie is so great']\n",
    "\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for _,col1 in final_df.iterrows():\n",
    "    head = col1['Entity2']\n",
    "    doc1 = nlp(head)\n",
    "    \n",
    "    for _,col2 in final_df.iterrows():\n",
    "        tail = col2['Entity2']\n",
    "        if head == tail:\n",
    "            continue\n",
    "            \n",
    "        doc2 = nlp(tail)\n",
    "        confidence = doc1.similarity(doc2)\n",
    "        \n",
    "        if confidence > 0.85:   # 85% seems to work pretty well\n",
    "            # Perform logic for linking\n",
    "            new_tail = head if len(tail)<len(head) else tail\n",
    "            \n",
    "            col1['Entity2'] = new_tail\n",
    "            col2['Entity2'] = new_tail\n",
    "\n",
    "            print(\"Sentence 1:\", doc1)\n",
    "            print(\"Sentence 2:\", doc2)\n",
    "            print(\"Similarity:\", confidence)\n",
    "            index += 1\n",
    "            print('Processed {} out of {}'.format(index,len(final_df)))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual Entailment with Keras_Parikh_Entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> https://github.com/explosion/spaCy/tree/master/examples/keras_parikh_entailment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_vectors_web_lg\n",
    "nlp = en_vectors_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Process & Entity Linking to existing Turtle Knowledge Bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "graph = rdflib.Graph()\n",
    "graph.parse('../data/starwars.ttl', format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"\"\"\n",
    "    SELECT ?s ?p ?o\n",
    "    WHERE {   \n",
    "        ?s ?p ?o.\n",
    "        #FILTER(?s=\"Darth Vader\")\n",
    "    }\n",
    "    #LIMIT 10\n",
    "\"\"\"\n",
    "res = graph.query(query_str)\n",
    "\n",
    "# for s,p,o in res:\n",
    "#     print(s, '->', p, '->', o)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
