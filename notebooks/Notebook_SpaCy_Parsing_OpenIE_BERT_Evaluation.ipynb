{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "import en_core_web_lg\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python -m spacy download en_trf_bertbaseuncased_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing & Part-of-Speech Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Text</b>: The original word text.<br>\n",
    "<b>Lemma</b>: The base form of the word.<br>\n",
    "<b>POS</b>: The simple UPOS part-of-speech tag.<br>\n",
    "<b>Tag</b>: The detailed part-of-speech tag.<br>\n",
    "<b>Dep</b>: Syntactic dependency, i.e. the relation between tokens.<br>\n",
    "<b>Shape</b>: The word shape – capitalization, punctuation, digits.<br>\n",
    "<b>is_alpha</b>: Is the token an alpha character?<br>\n",
    "<b>is_stop</b>: Is the token part of a stop list, i.e. the most common words of the language?<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Darth Vader is also known by his birth name Anakin Skywalker.')\n",
    "results = pd.DataFrame(columns=['Text', 'Lemma', 'POS', 'Tag', 'Dep', 'Shape', 'is_alpha', 'is_stop'])\n",
    "\n",
    "for token in doc:  \n",
    "    results = results.append({'Text':token.text, 'Lemma':token.lemma_, 'POS':token.pos_, 'Tag':token.tag_, 'Dep':token.dep_, 'Shape':token.shape_, 'is_alpha':token.is_alpha, 'is_stop':token.is_stop}, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svg = displacy.render(doc, style=\"dep\",jupyter=True)\n",
    "#output_path = Path(\"dep.svg\")\n",
    "#output_path.open(\"w\", encoding=\"utf-8\").write(svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entities (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Text</b>: The original entity text.<br>\n",
    "<b>Start</b>: Index of start of entity in the Doc.<br>\n",
    "<b>End</b>: Index of end of entity in the Doc.<br>\n",
    "<b>Label</b>: Entity label, i.e. type.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-829d98e68733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#doc = nlp('Darth Vader is also known by his birth name Anakin Skywalker.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Darth Vader is also known by his birth name Skywalker.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Start'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'End'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "#doc = nlp('Darth Vader is also known by his birth name Anakin Skywalker.')\n",
    "doc = nlp('Darth Vader is also known by his birth name Skywalker.')\n",
    "results = pd.DataFrame(columns=['Text', 'Start', 'End', 'Label'])\n",
    "\n",
    "for ent in doc.ents:  \n",
    "    results = results.append({'Text':ent.text, 'Start':ent.start_char, 'End':ent.end_char, 'Label':ent.label_}, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Larger Text Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Darth Vader, also known by his birth name Anakin Skywalker, is a fictional character in the Star Wars franchise.123 Vader appears in the original film trilogy as a pivotal antagonist whose actions drive the plot, while his past as Anakin Skywalker and the story of his corruption are central to the narrative of the prequel trilogy., The character was created by George Lucas and has been portrayed by numerous actors. His appearances span the first six Star Wars films, as well as Rogue One, and his character is heavily referenced in Star Wars: The Force Awakens. He is also an important character in the Star Wars expanded universe of television series, video games, novels, literature and comic books. Originally a Jedi prophesied to bring balance to the Force, he falls to the dark side of the Force and serves the evil Galactic Empire at the right hand of his Sith master, Emperor Palpatine (also known as Darth Sidious).4 He is also the father of Luke Skywalker and Princess Leia Organa, secret husband of Padmé Amidala and grandfather of Kylo Ren., Darth Vader has become one of the most iconic villains in popular culture, and has been listed among the greatest villains and fictional characters ever.56 The American Film Institute listed him as the third greatest movie villain in cinema history on 100 Years... 100 Heroes and Villains, behind Hannibal Lecter and Norman Bates.7 However, other critics consider him a tragic hero, citing his original motivations for the greater good before his fall to the dark side.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article = 'Darth Vader, also known by his birth name Anakin Skywalker, is a fictional character in the Star Wars franchise.123 Vader appears in the original film trilogy as a pivotal antagonist whose actions drive the plot, while his past as Anakin Skywalker and the story of his corruption are central to the narrative of the prequel trilogy., The character was created by George Lucas and has been portrayed by numerous actors. His appearances span the first six Star Wars films, as well as Rogue One, and his character is heavily referenced in Star Wars: The Force Awakens. He is also an important character in the Star Wars expanded universe of television series, video games, novels, literature and comic books. Originally a Jedi prophesied to bring balance to the Force, he falls to the dark side of the Force and serves the evil Galactic Empire at the right hand of his Sith master, Emperor Palpatine (also known as Darth Sidious).4 He is also the father of Luke Skywalker and Princess Leia Organa, secret husband of Padmé Amidala and grandfather of Kylo Ren., Darth Vader has become one of the most iconic villains in popular culture, and has been listed among the greatest villains and fictional characters ever.56 The American Film Institute listed him as the third greatest movie villain in cinema history on 100 Years... 100 Heroes and Villains, behind Hannibal Lecter and Norman Bates.7 However, other critics consider him a tragic hero, citing his original motivations for the greater good before his fall to the dark side.'\n",
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Dep</th>\n",
       "      <th>Shape</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>is_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Darth</td>\n",
       "      <td>Darth</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>compound</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vader</td>\n",
       "      <td>Vader</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>punct</td>\n",
       "      <td>,</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>also</td>\n",
       "      <td>also</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>advmod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>known</td>\n",
       "      <td>know</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>acl</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>dark</td>\n",
       "      <td>dark</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>side</td>\n",
       "      <td>side</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>punct</td>\n",
       "      <td>.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Text  Lemma    POS  Tag       Dep  Shape is_alpha is_stop\n",
       "0    Darth  Darth  PROPN  NNP  compound  Xxxxx     True   False\n",
       "1    Vader  Vader  PROPN  NNP     nsubj  Xxxxx     True   False\n",
       "2        ,      ,  PUNCT    ,     punct      ,    False   False\n",
       "3     also   also    ADV   RB    advmod   xxxx     True    True\n",
       "4    known   know   VERB  VBN       acl   xxxx     True   False\n",
       "..     ...    ...    ...  ...       ...    ...      ...     ...\n",
       "277     to     to    ADP   IN      prep     xx     True    True\n",
       "278    the    the    DET   DT       det    xxx     True    True\n",
       "279   dark   dark    ADJ   JJ      amod   xxxx     True   False\n",
       "280   side   side   NOUN   NN      pobj   xxxx     True    True\n",
       "281      .      .  PUNCT    .     punct      .    False   False\n",
       "\n",
       "[282 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(article)\n",
    "results = pd.DataFrame(columns=['Text', 'Lemma', 'POS', 'Tag', 'Dep', 'Shape', 'is_alpha', 'is_stop'])\n",
    "\n",
    "for token in doc:  \n",
    "    results = results.append({'Text':token.text, 'Lemma':token.lemma_, 'POS':token.pos_, 'Tag':token.tag_, 'Dep':token.dep_, 'Shape':token.shape_, 'is_alpha':token.is_alpha, 'is_stop':token.is_stop}, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford Open Information Extraction using CoreNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nlp.stanford.edu/software/openie.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting {entity1, relation, entity2} triples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openie import StanfordOpenIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with StanfordOpenIE() as client:\n",
    "    text = 'Darth Vader is also known by his birth name Anakin Skywalker.'\n",
    "    print('Text: %s.' % text)\n",
    "    \n",
    "    for triple in client.annotate(text):\n",
    "        print(triple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying longer document text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = []\n",
    "with StanfordOpenIE() as client:\n",
    "    print('Text: %s.' % article)\n",
    "    for triple in client.annotate(article):\n",
    "        triples.append(triple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of Entity-Relation triples: {len(triples)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://explosion.ai/blog/spacy-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_trf_bertbaseuncased_lg\n",
    "\n",
    "nlp = en_trf_bertbaseuncased_lg.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use word-level embeddings from BERT to add context to tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple1 = nlp(\"Apple shares rose on the news.\")\n",
    "apple2 = nlp(\"Apple sold fewer iPhones this quarter.\")\n",
    "apple3 = nlp(\"Apple pie is delicious.\")\n",
    "apple4 = nlp(\"Apple is a much better company than Microsoft.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(apple1[0].similarity(apple2[0]))\n",
    "print(apple1[0].similarity(apple3[0]))\n",
    "print(apple2[0].similarity(apple4[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_enc = nlp(article)\n",
    "vader_example = nlp('A popular dialogue from Darth Vader is, Luke I am your father.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_enc.similarity(vader_example) # average word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ' '.join(x for x in triples[0].values())\n",
    "article_enc.similarity(nlp(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check cosine similarity of each triple and original article and eliminate based on threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples_filtered = []\n",
    "threshold = 0.50\n",
    "for triple in triples:\n",
    "    statement = ' '.join(x for x in triple.values())\n",
    "    similarity = article_enc.similarity(nlp(statement))\n",
    "    if similarity > threshold:\n",
    "        triples_filtered.append(triple)\n",
    "    print(triple, similarity)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(triples), len(triples_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KG Creation & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starwars_graph = rdflib.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for triple in triples_filtered:\n",
    "    starwars_graph.add((\n",
    "        rdflib.Literal(triple['subject'], datatype=rdflib.namespace.XSD.string),\n",
    "        rdflib.Literal(triple['relation'], datatype=rdflib.namespace.XSD.string),\n",
    "        rdflib.Literal(triple['object'], datatype=rdflib.namespace.XSD.string)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, p, o in starwars_graph:\n",
    "    print(s, '->', p, '->', o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"\"\"\n",
    "    SELECT ?s ?p ?o\n",
    "    WHERE {   \n",
    "        ?s ?p ?o.\n",
    "        FILTER(?s='Darth Vader')\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "res = starwars_graph.query(query_str)\n",
    "for s,p,o in res:\n",
    "    print(s, '->', p, '->', o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"\"\"\n",
    "    SELECT ?s ?p ?o\n",
    "    WHERE {   \n",
    "        ?s ?p ?o.\n",
    "        FILTER(?s='Vader')\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "res = starwars_graph.query(query_str)\n",
    "for s,p,o in res:\n",
    "    print(s, '->', p, '->', o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"\"\"\n",
    "    SELECT ?s ?p ?o\n",
    "    WHERE {   \n",
    "        ?s ?p ?o.\n",
    "        FILTER(?s='He')\n",
    "    }\n",
    "\"\"\"\n",
    "res = starwars_graph.query(query_str)\n",
    "\n",
    "for s,p,o in res:\n",
    "    print(s, '->', p, '->', o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Need to \"contexualize\" key entities that group together \"He\" and \"Darth Vader\" for example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# starwars.ttl Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = rdflib.Graph()\n",
    "graph.parse('../data/starwars.ttl', format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"\"\"\n",
    "    SELECT ?s ?p ?o\n",
    "    WHERE {   \n",
    "        ?s ?p ?o.\n",
    "    }\n",
    "    LIMIT 10\n",
    "\"\"\"\n",
    "res = starwars_graph.query(query_str)\n",
    "\n",
    "for s,p,o in res:\n",
    "    print(s, '->', p, '->', o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse articles from Wikipedia and construct KG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackabuse.com/getting-started-with-pythons-wikipedia-api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia.search('Millennium Falcon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia.summary('Millennium Falcon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia.page('Millennium Falcon').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfalcon_article = wikipedia.page('Millennium Falcon').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_graph(article, similarity_threshold):\n",
    "    # Convert to triples\n",
    "    triples = []\n",
    "    with StanfordOpenIE() as client:\n",
    "        for triple in client.annotate(article):\n",
    "            triples.append(triple)\n",
    "    print(f'Num of Triples: {len(triples)}')\n",
    "    \n",
    "    # Load BERT\n",
    "    nlp = en_trf_bertbaseuncased_lg.load()\n",
    "    article_enc = nlp(article)\n",
    "    \n",
    "    # Similarity Thresholding\n",
    "    triples_filtered = []\n",
    "    for triple in triples:\n",
    "        statement = ' '.join(x for x in triple.values())\n",
    "        similarity = article_enc.similarity(nlp(statement))\n",
    "        if similarity > similarity_threshold:\n",
    "            triples_filtered.append(triple)\n",
    "    print(f'Filtered Triples: {len(triples_filtered)}')\n",
    "    \n",
    "    # Need to add step here for contexualization\n",
    "    \n",
    "    # Create RDF graph\n",
    "    graph = rdflib.Graph()\n",
    "    for triple in triples_filtered:\n",
    "        graph.add((\n",
    "            rdflib.Literal(triple['subject'], datatype=rdflib.namespace.XSD.string),\n",
    "            rdflib.Literal(triple['relation'], datatype=rdflib.namespace.XSD.string),\n",
    "            rdflib.Literal(triple['object'], datatype=rdflib.namespace.XSD.string)\n",
    "        ))\n",
    "    \n",
    "    return graph\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = text_to_graph(article=article, similarity_threshold=0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"\"\"\n",
    "    SELECT ?s ?p ?o\n",
    "    WHERE {   \n",
    "        ?s ?p ?o.\n",
    "    }\n",
    "\"\"\"\n",
    "res = graph.query(query_str)\n",
    "heads, relations, tails = {}, {}, {}\n",
    "\n",
    "index = 0\n",
    "for s,p,o in res:\n",
    "    heads[index] = str(s)\n",
    "    relations[index] = str(p)\n",
    "    tails[index] = str(o)\n",
    "    index += 1\n",
    "    #print(s, '->', p, '->', o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node, Index pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads, tails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate term pairs for LexNet3: Evaluate hypernym relationship with every head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_pairs = {}\n",
    "for key1,_ in heads.items():\n",
    "    for key2,_ in heads.items():\n",
    "        pair = (heads[key1], heads[key2])\n",
    "        term_pairs[pair] = 'false'    # false doesnt mean anything, satisfies code\n",
    "print(len(term_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilize LexNet3 for Hypernym Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from LexNET3.lstm_common import vectorize_path, load_dataset, load_embeddings, get_paths\n",
    "from LexNET3.knowledge_resource import KnowledgeResource\n",
    "from LexNET3.paths_lstm_classifier_tf import PathLSTMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_prefix = '/Users/rhythmsyed/Desktop/GTRI/entitylink/resource/wiki'\n",
    "dataset_prefix = '/Users/rhythmsyed/Desktop/GTRI/entitylink/LexNET3/datasets/KHN'\n",
    "model_prefix_file = '/Users/rhythmsyed/Desktop/GTRI/entitylink/models/customKH_model_checkpt/lstm_integrated_0.00_10'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_prefix + '/relations.txt', 'r', encoding='utf-8') as f_in:\n",
    "    relations = [line.strip() for line in f_in]\n",
    "    relation_index = {relation: i for i, relation in enumerate(relations)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "print('Loading the dataset...')\n",
    "test_set = load_dataset(dataset_prefix + '/test.tsv', relations)\n",
    "y_test = [relation_index[label] for label in list(test_set.values())]\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the resource (processed corpus)\n",
    "print('Loading the corpus...')\n",
    "corpus = KnowledgeResource(corpus_prefix)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "classifier, word_index, pos_index, dep_index, dir_index = PathLSTMClassifier.load_model(model_prefix_file)\n",
    "print('Model Loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import count\n",
    "def load_paths_and_word_vectors(corpus, dataset_keys, lemma_index):\n",
    "    \"\"\"\n",
    "    Load the paths and the word vectors for this dataset\n",
    "    :param corpus: the corpus object\n",
    "    :param dataset_keys: the word pairs in the dataset\n",
    "    :param word_index: the index of words for the word embeddings\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the dictionaries\n",
    "    pos_index = defaultdict(count(0).__next__)\n",
    "    dep_index = defaultdict(count(0).__next__)\n",
    "    dir_index = defaultdict(count(0).__next__)\n",
    "\n",
    "    dummy = pos_index['#UNKNOWN#']\n",
    "    dummy = dep_index['#UNKNOWN#']\n",
    "    dummy = dir_index['#UNKNOWN#']\n",
    "\n",
    "    # Vectorize tha paths (this calculates p_xy for the corpus\n",
    "    # Note: vectorize path calls vectorize edge, which computes the edge\n",
    "    keys = [(corpus.get_id_by_term(str.encode(x)), corpus.get_id_by_term(str.encode(y))) for (x, y) in dataset_keys]\n",
    "    paths_x_to_y = [{vectorize_path(path, lemma_index, pos_index, dep_index, dir_index): count\n",
    "                     for path, count in get_paths(corpus, x_id, y_id).items()}\n",
    "                    for (x_id, y_id) in keys]\n",
    "    paths = [{p: c for p, c in paths_x_to_y[i].items() if p is not None} for i in range(len(keys))]\n",
    "\n",
    "    empty = [dataset_keys[i] for i, path_list in enumerate(paths) if len(list(path_list.keys())) == 0]\n",
    "    print('Pairs without paths:', len(empty), ', all dataset:', len(dataset_keys))\n",
    "\n",
    "    # Get the word embeddings for x and y (get a lemma index)\n",
    "    print('Getting word vectors for the terms...')\n",
    "    x_y_vectors = [(lemma_index.get(x, 0), lemma_index.get(y, 0)) for (x, y) in dataset_keys]\n",
    "\n",
    "    pos_inverted_index = {i: p for p, i in pos_index.items()}\n",
    "    dep_inverted_index = {i: p for p, i in dep_index.items()}\n",
    "    dir_inverted_index = {i: p for p, i in dir_index.items()}\n",
    "\n",
    "    print('Done loading corpus data!')\n",
    "\n",
    "    return x_y_vectors, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the paths and create the feature vectors\n",
    "print('Loading path files...')\n",
    "x_y_vectors_test, x_test = load_paths_and_word_vectors(corpus, list(term_pairs.keys()), word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Evaluation:')\n",
    "pred = classifier.predict(x_test, x_y_vectors=x_y_vectors_test)\n",
    "len(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check relation classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified = {}\n",
    "res = dict((v,k) for k,v in relation_index.items())\n",
    "for index in enumerate(term_pairs.items()):\n",
    "    classified[index[1][0]] = res[pred[index[0]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in classified.items():\n",
    "    if value != 'false':\n",
    "        print(key, '->', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
